\documentclass[a4paper,12pt]{article}
\usepackage[T2A]{fontenc}
\usepackage[russian]{babel}
\usepackage[utf8]{inputenc}
\usepackage{indentfirst}
\usepackage{url}
\date{}

\begin{document}
	\begin{titlepage}
		\begin{center}
			\large Московский Государственный Университет им. М.В.Ломоносова\\[4,5cm]
			\huge Конспект лекций \\[0,6cm]
			\large по курсу "Распределённые операционные системы"\\[3,7cm]
			\vspace{2cm}
			\begin{flushright}
						\emph{Автор:} Нокель Михаил\\
						\emph{Группа:} 420\\
						\emph{Факультет:} ВМК\\
						\emph{Лектор:} Крюков Виктор Алексеевич, Бахтин Владимир\\
			\end{flushright}					
			\vfill
			{\large \today}
			{\large \LaTeX}			
		\end{center}
	\thispagestyle{empty}			
	\end{titlepage}
	\newpage
	\tableofcontents
	\thispagestyle{empty}
	\newpage
	\section{\bf Лекция 1. История операционных систем}
	\centerline{12 февраля}
	Периоды:
	\begin{enumerate}
		\item {\em 1940-1950-е годы}: "использование машин как персональных ЭВМ". Доступ 
		предоставлялся монопольно одному пользователю.
		Появились компоненты -- предшественники ОС: 
		\begin{enumerate}
			\item управляющая программа, обеспечивающая интерфейс с пользователем.
			\item программы управления вводом/выводом.
		\end{enumerate}
		\item {\em 1950-е годы}: пакетная обработка. Потребовались новые возможности:
		\begin{enumerate}
			\item механизмы защиты ОП (проверка по адресу с помощью двух регистров: начала и 
			конца доступной памяти)
			\item механизмы защиты диска -- введение привилегированного режима
			\item механизм прерываний:
			\begin{itemize}
				\item передача управления с сохранением информации на диске
				\item передача управления с сохранением информации в стеке
				\item передача управления в виде сообщений ОС
			\end{itemize}
			\item механизм таймера
		\end{enumerate}
		Если какого-то компонента не хватает, то для реализации мультипрограммного режима
		необходима интерпретация, а это очень сильное замедление программ.
		\item {\em Середина 1960-х годов}: режим разделения времени (РРВ). Появление:
		\begin{enumerate}
			\item терминала (устройства ввода/вывода, посылки сигнала ОС)
			\item квантования времени
			\item страничной и сегментной организации памяти (сегментная - для контроля за 
			деятельностью программиста) -> сегментно-страничной организации памяти
		\end{enumerate}
		Появление multix.
		\item {\em Середина 1970-х годов}: появление многомашинных комплексов, многопроцессорных 
		ЭВМ и сетей ЭВМ. Цели появления: специализация, эффективность и надёжность.	
	\end{enumerate}
	\section{\bf Лекция 2. История операционных систем (продолжение)}
	\centerline{19 февраля}
	Многомашинные комплексы -- системы компьютеров с общими дисками (где помещался буфер ввода
и буфер вывода). Также они могут быть связаны через каналы связей.
	Сети позволяют произвольное количество произвольных мащин подключать. Произошло разделение
функций между ОС и протоколами передачи данных. Обеспечивали новые три функции:
	\begin{itemize}
		\item диалог с пользователем. Потребовалась работа с удалённой ЭВМ. Появились 
		виртуальные терминалы.
		\item доступ к файлам. Запросы к файлам должны быть оттранслированы на машину, где эти 
		файлы располагаются. Появление распределённых файловых систем.
		\item запуск в пакетном режиме.
	\end{itemize}
	\begin{enumerate}
		\item {\em 80-е годы}: появление ПЭВМ (персональных ЭВМ). Отличительные особенности: 
		ПЭВМ обладали экраном и большой мощностью процессора, приходящейся на одного 
		пользователя. Отрабатывались новые возможности взаимодействия с ОС. ОС в начале этого 
		периода были однопользовательскими и однозадачными. Функции распределения ресурсов 
		отсутствовали. Потом появилась сегментная организация памяти (начиная с 86х 
		процессоров). В середине 80х годов появились 386е процессоры с сегментно-страничной 
		памятью. ОС за это десятилетие усложнились и не уступали по возможностям тем ОС, 
		которые работал на больших ЭВМ.
		\item {\em 90-е годы}: появление MPP - многопроцессорной ЭВМ с распределённой памятью; 
		открытых систем, Интернета. В 1992 году самой производительной стала машина MPP с 
		распределённой памятью. И с тех пор они и до сих пор являются лидерами. Способствовали 
		этому 2 основные причины:
		\begin{enumerate}
			\item работа с общей памятью: расположить много процессоров вокруг общей памяти - 
			проблема.
			\item поддержка согласованного состояния КЭШ-памяти (в случае если много 
			процессоров есть с общей памятью). Решение: использование сквозного КЭШ. Достигается 
			путём введения общей шины между процессорами, которую можно ''подслушать''.
		\end{enumerate}
		Постепенно в узлах MPP стали поддерживаться UNIX-системы, потом и Windows-системы. Но
		традиционные ЭВМ не справлялись с поставленными задачами: работа с большим количеством 
		сетевых портов, например. Самая тонкая проблема: традиционные ОС использовали примерно 
		1\% на свои нужды, из-за чего возникали простои. Решение: своеобразная настройка ОС.
		Открытые системы - это стандартизация работы машин, на которых работают различные ОС. В
		результате стало возможным создание Интернет.
		\item {\em 2000-е года}: появление и распространение кластеров, распределённых систем, 
		ГРИД-систем.
		Достоинство кластеров: широкая доступность.
		Сейчас идёт переход на многоядерные системы. Возникают проблемы:
		\begin{enumerate}
			\item проблема написания ПО
			\item энергопотребление
			\item проблема быстродействия памяти и быстродействия кристалла. В результате 
			появились многопоточные процессоры. Суть: процессор работает не с одним потоком, а 
			с несколькими, и переключение между ними идёт аппаратно.
		\end{enumerate}
		Все эти тенденции отражались в графических процессорах.
		Ещё в 1990х годах появились метакомпьютеры, впоследствии перешедшие в ГРИД. Сейчас
		широко используется и распространяются "облачные вычисления". Они позволяют не 
		задумываться о конкретике, предоставляются только сервисы. 
	\end{enumerate}
	\subsection{\bf Причины создания распределённых систем}
	\begin{enumerate}
		\item Экономическая причина. Закон Гроша: быстродействие процессора пропорционально
		квадрату его стоимости. Перестал действовать в 80х годах с появлением микропроцессоров.
		\item Достижение высокой производительности путём объединения многих процессоров.
		\item Наращивание производительности.
	\end{enumerate}
	\section{\bf Лекция 3. Коммуникации в распределённых системах}
	\centerline{26 февраля}
	Материалы по курсу лежат по следующим адресам:
	\begin{itemize}
		\item \url{http://sp.cs.msu.su/courses/os/distr-os-2010.zip}
		\item \url{ftp://ftp.keldysh.ru/K_student/distr-os-2010.zip}
	\end{itemize}
	Существуют 2 операции по передаче сообщений между машинами в распределённой системе:
	\begin{enumerate}
		\item послать (кому, адрес\_начала, длина\_сообщения)
		\item принять (кому, адрес\_памяти(куда), длина\_сообщения)
	\end{enumerate}
	При этом сообщение должно помещаться в выделенной памяти. Часто нужно как-то различать
приходящие сообщения. Для этого добавляют теги - типы сообщений.

	Существуют 2 способа пересылки сообщений:
	\begin{enumerate}
		\item синхронный
		\item асинхронный (в этом случае надо добавить буферы)
	\end{enumerate}
	Формула для вычисления времени передачи сообщения:
$$T=T_s+T_b*L,$$
	где $T_s$ -- время старта (аппаратная составляющая), $T_b$ -- время передачи байта,
$L$ -- длина сообщения.

	Существуют 2 архитектуры распределённых систем:
	\begin{enumerate}
		\item {\em транспьютерная решётка}. Появилась в первой половине 80-х годов. Обладает 
		двумя особенностями:
		\begin{enumerate}
			\item система команд: самые часто встречающиеся команды упаковываются в 1 байт 
			(всего таким образом можно 15 команд упаковать)
			\item функции планировщика процессов реализованы аппаратно.
		\end{enumerate}
		У каждого транспьютера было по 4 входных/выходных канала. Следовательно, сообщения
		могли идти разными путями. Для ускорения передачи сообщений существуют 2 метода 
		ускорения:
		\begin{enumerate}
			\item разбиение сообщения на части при передаче, а части передаются разными 
			маршрутами
			\item организация конвейера (разделение сообщение на k частей для организации 
			полного зацепления). Возникает проблема: определить k оптимально.
		\end{enumerate}
		Это были быстрые процессоры своего времени. Но транспьютеры следующего поколения не
		получились. Поэтому стали подвешивать к узлам процессоры Intel.
		\item {\em сеть с шинной организацией}.  Особенности:
		\begin{enumerate}
			\item в 1 момент времени передаётся только 1 сообщение (нельзя передавать 
			параллельно)
			\item арбитр шины разрешает возникающие коллизии
			\item можно передать 1 сообщение сразу всем
		\end{enumerate}
		Существуют 2 способа передачи:
		\begin{enumerate}
			\item с широковещанием
			\item без широковещания
		\end{enumerate}
	\end{enumerate}
	Обе архитектуры на данный момент не соответствуют действительности:
	\begin{enumerate}
		\item много сетей существуют для параллельного обмена
		\item много способов, чтобы сделать пути неодинаковыми
	\end{enumerate}
	\subsection{\bf MPI}
	\centerline{\bf Message Passing Interface}
	Появился в 1994 году. Цели создания:
	\begin{enumerate}
		\item создать интерфейс прикладного программирования
		\item обеспечить возможности эффективной коммуникации (убрать лишнее копирование в/из 
		канала)
		\item разрешить расширения для использования в гетерогенных системах
		\item исходить из надёжности коммуникации (имеется проблема надёжности)
		\item определить интерфейс, не очень сильно отличающийся от тех, что использовали раньше
		\item интерфейс должен быть быстро переделан
	\end{enumerate}
	Были включены:
	\begin{enumerate}
		\item коммуникации типа "точка-точка"
		\item коллективные операции
		\item понятие группы процессов
		\item коммуникационный контекст
		\item топология процессов
	\end{enumerate}
	Все операции были синхронными или асинхронными, блокирующими или неблокирующими.
	
	Неблокирующие операции - управление возвращается сразу же. Блокирующие операции - сообщение
копируется в системный буфер, управление возвращается процессору.

	Send/receive:
	\begin{itemize}
		\item адрес буфера в памяти
		\item количество элементов
		\item тип данных
		\item номер процессора в группе
		\item тег сообщения
		\item коммуникатор (объединение понятия группы и контекста)
	\end{itemize}
	Для команды "receive" номер процессора в группе и тег сообщения могут не указываться, но
зато обязательно добавляется статус, с помощью которого можно узнать тег, номер процессора, 
количество сообщений.
	
	Существуют 4 режима посылки сообщений:
	\begin{enumerate}
		\item стандартный
		\item буферизуемый
		\item синхронный
		\item готовности
	\end{enumerate}
	И соответственно 4 префикса:
	\begin{enumerate}
		\item B - Block
		\item S - Sync
		\item R - Ready
		\item I - для неблокирующих операций
	\end{enumerate}
	Одной из стандартных ошибок при реализации пересылки сообщений являются тупики.
	
	Коллективные операции:
	\begin{enumerate}
		\item Барьер
		\item Передача всем от одного (broadcast)
		\item Сбор данных от всех (gather)
		\item Рассылка всем (scatter)
		\item Сбор всех от всех (all gather)
		\item Рассылка всем от всех (all to all)
		\item Глобальные операции (редукция)
	\end{enumerate}
	В 1997 году появился MPI-2.0. Нововведения:
	\begin{enumerate}
		\item односторонние коммуникации
		\item динамическое создание/удаление процессов
		\item параллельный ввод/вывод
	\end{enumerate}
	\section{\bf Лекция 4. Синхронизация распределённых систем}
	\centerline{5 марта 2010 г.}
	Выделяют 2 вида синхронизации:
	\begin{enumerate}
		\item взаимное исключение (в системах с общей памятью)
		\item координация процессов (один процесс сделал работу и сообщает другим, что можно
		воспользоваться его результатами)
	\end{enumerate}
	К {\em взаимному исключению} предъявляются следующие требования\footnote {Будем считать
	синонимами "критическая секция" и "критический интервал". Также будем использовать
	термины: "вход и выход в критическую секцию (интервал)"}:
	\begin{enumerate}
		\item 1 процесс может только находиться в критической секции
		\item Если критическая секция свободна, то вход без задержки (конечно, всегда есть
		задержка на реализацию входа, но это незначительное время)
		\item Нет бесконечного ожидания при условии, что $T_{KS}<\infty$
		\item Нет никаких предположений относительно скоростей
	\end{enumerate}
	Возможны следующие механизмы синхронизации:
	\begin{enumerate}
		\item Логическое время. Необходима синхронизация времени между процессами, чтобы не было
		абсурда. Если получилось, что $T_{receive}<T_{send}$, то прибавим что-нибудь к 
		$T_{receive}$, чтобы получилось наоборот.
		\item Каналы FIFO -- каналы, связывающие два процесса и работающие по принципу FIFO
		(раньше отправили -- раньше пришло). В MPI есть правило: если один процесс посылает
		другому сообщения с одним тегом, то они приходят в порядке отправки.
		\item Неделимое широковещание -- широковещание, обеспечивающее приход всех сообщений в 
		одном и том же порядке.
		\item Выбор координаторов. Координатор -- процесс, выполняющий особую роль. Задача
		состоит в выборе координатора. Существуют 2 алгоритма выбора:
		\begin{enumerate}
			\item "Задира". Логика: k-й процесс обнаружил, что предыдущий координатор перестал
			отвечать. Запускается выбор координатора. Посылается номер своего процесса всем
			процессам с большими, чем у него номерами. Каждый, кто "жив" скажет, что "я беру 
			выборы на себя". Всегда найдётся процесс с наибольшим номером среди живых, и он 
			становится координатором. Но алгоритм не детерминирован: непонятно, кому вначале
			отсылать сообщения. От этого зависит скорость выборов.
			\item Круговой. Логика: все процессы связаны в какое-то логическое кольцо. Первый,
			кто обнаружил неработоспособность, начинает отправлять сообщение со своим номером
			своему соседу. Каждый следующий добавляет свой номер к уже существующим. После
			первого круга инициировавший выборы получает список всех живых процессов. На втором
			круге все узнают нового координатора (процесса с наибольшим номером).
		\end{enumerate}
	\end{enumerate}
	Существуют следующие требования к децентрализованным алгоритмам:
	\begin{enumerate}
		\item Вся информация распределена между процессами. Пример: нет единого телефонного
		справочника.
		\item Процессы принимают решения на основе локальной информации.
		\item Не должно быть единственной критической точки, выход из строя которой приведёт к
		краху алгоритма. Это требование надёжности.
		\item Нет единого времени\footnote{Имеется в виду физическое время}. Добиться единого
		времени очень сложно, поэтому не должно быть к этому привязки.
	\end{enumerate}
	Рассмотрим теперь алгоритмы взаимного исключения:
	\begin{enumerate}
		\item Централизованный. Среди множества процессов имеется 1 процесс-координатор. Каждый,
		кто хочет войти в критическую секцию, посылает координатору запрос. Координатор
		справедливо выдаёт право на вход в критическую секцию. Кто, первый послал, тот и получил
		разрешение на вход. В момент выхода процесс посылает координатору сообщение о том, что
		он вышел. Таким образом, всего требуются 3 сообщения.
		\item Децентрализованный с временными метками. Каждый процесс спрашивает у всех
		остальных на предмет того, может ли он войти в критическую секцию. Каждый, кто получил
		его и кто не находится в критической секции и которому не нужен вход в критическую
		секцию, отвечает ему. Если процесс сам хочет войти в критическую секцию, то с помощью
		логического времени осуществляется сравнение своей метки с временем процесса, пославшего
		запрос\footnote{Совпасть временные метки не могут!}. Вход даётся только, если получены
		разрешения от всех процессов. В итоге потребуется $2*(n-1)$ запросов, где $n$ --
		количество процессов.
	
		Возникает вопрос: "А можно ли ускорить децентрализованный алгоритм?" При наличии 
		неделимых широковещательных рассылок можно было бы отказаться от логического времени 
		и получить выигрыш.
		\item Маркерные алгоритмы. Тот, у кого есть маркер, может входить в критическую	секцию.
		\begin{enumerate}
			\item круговой. Все процессы связаны в логическое кольцо, и передаётся маркер. Тот,
			у кого есть маркер, может войти в критическую секцию. После выхода маркер передаётся
			соседу по кругу. Самый эффективный, если все хотят в критическую секцию -- всего 1
			сообщение на вход/выход.
			\item широковещательный. Процесс все раздаётся запрос о том, что требуется маркер.
			И от владельца каким-то образом получит потом. Решение: 
			\begin{itemize}
				\item организовать очередь запросов (длина N).
				\item ввести нумерацию запросов -- организовать массив с номерами последних
				удовлетворённых запросов $LN[1...N]$
			\end{itemize}
			При входе в критическую секцию:
			\begin{itemize}
				\item процесс k имеет вектор $RN_k[k]+1$ и широковещательный запрос и должным
				образом корректирует вектор.
				\item при этом если есть маркер, то просто вход в критическую секцию
			\end{itemize}
			При выходе из критической секции:
			\begin{itemize}
				\item коррекция массива $LN$. Если j-й процесс вышел, то корректируем $LN[j]$
				\item новые запросы получаем из сравнения векторов $RN$ и $LN$ и помещаем их
				в очередь, предварительно проверив, что их там ещё нет.
			\end{itemize}		
			\item древовидный. Идея: построение дерева процессов. Маркер будет найден, 
			медленнее, но с меньшими затратами, чем в случае с широковещательным.
			
			Все процессы выстроены в некоторое сбалансированное дерево и у каждой
			вершины-процесса есть:
			\begin{itemize}
				\item указатель в ту сторону, где находиться владелец маркера.
				\item очередь из тех, кому нужен маркер:
				\begin{itemize}
					\item себе
					\item соседу сверху
					\item соседу снизу слева
					\item соседу снизу справа
				\end{itemize}
			\end{itemize}
			Главное отличие -- отсутствие единой очереди, как в случае с широковещательным
			алгоритмом.
			
			При входе в критическую секцию:
			\begin{itemize}
				\item Есть маркер $\rightarrow$ входим.
				\item Иначе $\rightarrow$ помещаем свой запрос в свою очередь.
				\item Посылаем сообщение "ЗАПРОС"
			\end{itemize}
			Получили сообщение:
			\begin{itemize}
				\item Если получили маркер:
				\begin{itemize}
					\item[M1] Взять первый из очереди
					\item[M2] Послать маркер автору (возможно и себе)
					\item[M3] Поменять указатель (в сторону владельца маркера)
					\item[M4] Исключить запрос, который был первым в очереди
					\item[M5] Если в очереди остались запросы (т.е. маркер нам нужен), 
					то послать сообщение-запрос в сторону маркера
				\end{itemize}
				\item Если получили запрос:
				\begin{itemize}
					\item Помещаем в очередь
					\item Если нет маркера, посылаем запрос в сторону маркера\footnote{
					нет смысла посылать запрос в сторону маркера повторно}
					\item Если есть маркер, переход на пункт "M1" (разобраться с очередью)
				\end{itemize}
			\end{itemize}
			При выходе из очереди, снова на "M1" (если очередь не пуста)		
		\end{enumerate}
	\end{enumerate}
	Перейдём к рассмотрению координаторов процессов.
	\begin{enumerate}
		\item Если известен производитель и потребитель, то посылаем сообщение "точка-точка"
		\item Если неизвестен потребитель, то:
		\begin{itemize}
			\item либо всем
			\item либо по запросу
		\end{itemize}
		\item Если неизвестен ни производитель, ни потребитель, то либо:
		\begin{itemize}
			\item через координатора
			\item широковещательный запрос
		\end{itemize}		
	\end{enumerate}
	\section{\bf Лекция 5. Многопроцессорные системы}
	\centerline{12 марта 2010 г.}
	\centerline{Владимир Бахтин\footnote{Много скучного неинтересного кода и абсолютное 
неумение вести лекцию}}
	Есть разрыв между временем доступа к памяти и скоростью работы процессора. На примере
Itanium 2:
	\begin{itemize}
		\item для доступа к памяти L1 - 1-2 такта
		\item для доступа к памяти L2 - 5-7 тактов
		\item для доступа к memory 180-225 тактов
	\end{itemize}
	При этом если увеличить производительность процессора, то выигрыш будет незначительным.
Так появилась идея переключения между выполняемыми потоками, за счёт чего получился серьёзный
прирост производительности.

	{\em Процесс} - некоторое выполнение программы, с которым связана следующая информация:
	\begin{enumerate}
		\item Таблица страниц
		\item Дескрипторы открытых файлов
		\item Запросы на ввод/вывод
		\item и др.
	\end{enumerate}		
	Что же касается нитей, то в рамках одного процесса может быть запущено N нитей. У них
может быть общая память, через которую они могут взаимодействовать. С ними связана следующая
информация:
	\begin{enumerate}
		\item Регистр
		\item Счётчик команд
		\item Стек
	\end{enumerate}
	Т.к. существует проблема энергопотребления, то появилась идея снижения частоты процессора 
(и как следствие, энергопотребления) и разбиения на несколько ядер (в результате получаем
выигрыш). Пример четырёхядерного процессора - Intel Core I7. У AMD есть на данный момент 
шестиядерный Opteron, так же есть ещё Niagara II и др.
	
	Способы организации многопроцессорных систем:
	\begin{enumerate}
		\item Главный-подчинённый (master-slave)
		\item Симметричный
	\end{enumerate}
	Процессы бывают двух типов:
	\begin{enumerate}
		\item Взаимодействующие
			\begin{enumerate}
				\item разделение памяти
					\begin{enumerate}
						\item Оперативная память
						\item Внешняя память
					\end{enumerate}
				\item обмен сообщениями
			\end{enumerate}
		\item Независимые
	\end{enumerate}
	Рассмотрим пример:
	
	Пусть имеются 2 процесса:
	\begin{enumerate}
		\item $P0:\mbox{ } x=x+1$
				
		$LOAD\mbox{ } R1,X$
		
		$ADD\mbox{ } R1,1$
		
		$STORE\mbox{ } R1,x$
		\item $P1:\mbox{ } x=x-1$
		
		$LOAD\mbox{ } R1,X$
		
		$SUB\mbox{ } R1,1$
		
		$STORE\mbox{ } R1,X$
	\end{enumerate}
	Возможный способ выполнения команд:
	$$
	\begin{array}{ccc}
		t & P0 & P1 \\
		0 & LOAD\mbox{ } R1,X \\
		1 & ADD\mbox{ } R1,1 & LOAD\mbox{ } R1,X \\
		2 & STORE\mbox{ } R1,X & SUB\mbox{ } R1,1 \\
		3 & & STORE\mbox{ } R1,X \\
	\end{array}
	$$
	Как видно, в итоге получим значение счётчика, равное -1. Это одно из трёх возможных
значений. То есть в зависимости от устройства конкретной машины можно получить абсолютно различные
значения. Подобные ошибки трудно обнаружить и с ними трудно бороться.

	Для борьбы используется ряд синхронизационных конструкций. Введём следующие требования:
	\begin{enumerate}
		\item В любой момент времени в критическом интервале может находиться только 1 процесс
		\item Если в критическом интервале нет процессов, то должны получить разрешение на вход
		без задержки
		\item Ни один процесс не должен ждать бесконечно долго разрешения на вход
		\item Не должны учитывать производительность процессов
	\end{enumerate}	
	Существуют 2 режима возможного выполнения (применялись на однопроцессорных системах):
MONO/MULTI. Если процесс хотел завладеть единолично, то он запускался в режиме MONO.

	Очевидно, для многопроцессорных систем это не подходило. Поэтому были разработаны 
различные алгоритмы:
	\begin{enumerate}
		\item Алгоритм Дейкера:\footnote{Работает не всегда: например, в случае распределённых
		систем не будет работать из-за того, что алгоритм предполагает неделимость операции
		чтения/записи, а в случае распределённых систем это не так (всегда есть задержки)}
		
		{\bf {proc(0) \&\& proc(1)
		
		int turn;
		
		boolean flag[2];
		
		turn i=0;
		
		flag[0]=flag[1]=FALSE;
		\newline
		\newline
		proc(int i) \{
		
			\qquad while(true) \{
		
				\qquad \qquad <вычисления$_i$>
			
				\qquad \qquad enter\_region(i)
			
				\qquad \qquad <критический интервал>
			
				\qquad \qquad leave\_region(i)
			
			\qquad \}
		
		\}
		\newline
		void enter\_region(int i) \{
			
			\qquad try:
			
				\qquad \qquad flag[i]=TRUE;
				
				\qquad \qquad while(flag[(n+1)\%]) \{
					
					\qquad \qquad \qquad if (turn==i) continue;
					
					\qquad \qquad \qquad flag[i]=FALSE;
					
					\qquad \qquad \qquad while(turn!=i);
					
					\qquad \qquad \qquad goto try;
					
			\qquad \}
		
		\}
		\newline
		void leave\_region(int i) \{
		
			\qquad turn=(i+1)\%2;
			
			\qquad flag[i]=FALSE;
			
		\} }}
		
		\item Алгоритм Петерсона. Отличается от предыдущего лишь функцией входа в критический
		интервал.
		
		{\bf {void enter\_region(int i) \{
			
			\qquad int other;
			
			\qquad other=1-i;
			
			\qquad flag[i]=TRUE;
			
			\qquad turn=i;
			
			\qquad while((turn==i)\&\&(flag[other]==TRUE)) ;
			
		\}
		\newline
		void leave\_region(int i) \{
		
			\qquad flag[i]=FALSE;
			
		\} }}
		\item Алгоритм для любого числа процессов. Введём дополнительную функцию:
		
		{\bf {TEST AND SET LOCK
		
			\qquad tsl(r,s) [r=s; s=1] }}
		\newline
		Теперь реализуем функции входа/выхода:\footnote{код на ассемблере!}
		
		{\bf {inter\_region: tsl reg,flag
		
			\qquad cmp reg,0
			
			\qquad jnz enter\_region
			
			\qquad ret
			
			leave\_region: move flag,\#0
			
			\qquad ret}}
		\item Алгоритм семафоров Дейкстры. У всех вышеперечисленных алгоритмов есть недостаток 
		-- активное ожидание. Решение предложил Дейкстра:
		
		{\bf {P(S) [if (s==0) <заблокировать текущий процесс> else s=s-1]}} -- функция
		захвата семафора
		
		{\bf {V(S) [if (s==0) <разблокировать один из ранее заблокированных процессов>; s=s+1]}}
		-- функция освобождения семафора
		
		Пример использования семафора:
		
		{\bf {proc (int i) \{
		
			\qquad while (TRUE) \{
			
				\qquad \qquad <вычисления>
				
				\qquad \qquad P(S)
				
				\qquad \qquad <КИ>
				
				\qquad \qquad V(S)
			
			\qquad \}
		
		\} }}
	\end{enumerate}
	\section{\bf Лекция 6. Синхронизация многопроцессорных систем (продолжение)}
	\centerline{19 марта 2010 г.}
	Напомним:
	
	{\bf {P(S) [if (s==0) <Заблокировать процесс> else s=s-1]}}
	
	{\bf {V(S) [if (s==0) <Разблокировать один процесс> s=s+1]}}
	
	Рассмотрим задачу производителей и потребителей. Для её реализации используем 3 семафора:
	
	{\bf {semaphore s=1;
	
		semaphore empty=N;
		
		semaphore full=0;
	\newline
	\newline
	producer() \{
		int item;
		while(TRUE) \{
		
			\qquad produce\_item(\&item);
			
			\qquad P(empty);
			
			\qquad P(S);
			
			\qquad enter\_item(item);
			
			\qquad V(S);
			
			\qquad V(full);
			
		\}
	\newline		
	\}
	\newline
	consumer() \{
		
		int item;
		
		while(TRUE) \{
			
			\qquad P(full);
			
			\qquad remove\_item(\&item);
			
			\qquad V(S);
			
			\qquad V(empty);
			
			\qquad consume\_item(item);
			
		\}
	\newline	
	\} }}
	
	Приведём пример из мира Unix:
	
	{\bf {\#include <pthread.h>
	
		pthread\_mutex\_t mutex=PTHREAD\_MUTEX\_INITIALIZER;
		
		pthread\_mutex\_lock(\&mutex); //P(mutex)
		
		pthread\_mutex\_unlock(\&mutex); //V(mutex)
		
		pthread\_mutex\_trylock(\&mutex); //возврат код ответа}}
		
	Если потребителей много, то семафоры здесь не справятся. Необходим другой механизм, а 
именно механизм {\em событий}.

	Вводятся следующие операции для работы с событиями:
	\begin{enumerate}
		\item POST(S)
		\item WAIT(S)
		\item CLEAR(S)
	\end{enumerate}
	
	Разница между семафорами о событиями существенная. При выполнении V(S) будет разблокирован
один процесс, а при выполнении POST(S) -- все процессы (вся очередь). В принципе, эти понятия
очень похожи и можно попробовать реализовать один механизм через другой. К примеру, можно
реализовать события через семафоры: при выполнении POST(S) берём все процессы из очереди и для
каждого выполняем P(S),V(S).

	Рассмотрим следующий алгоритм в качестве примера:
	
	{\bf {for (i=1;i<L1-1;i++) \{
	
		\qquad for j=1;j<L2-1;j++) \{
		
			\qquad \qquad A[i][j]=(A[i-1][j]+A[i][j-1]+A[i][j]+A[i][j+1])/4;
			
		\qquad \}
		
	\} }}

	Заметим, что витки этого цикла можно выполнять параллельно. Реализовать это можно 
по-разному: можно циклически, можно давать тому, кто раньше закончил и т.д.

	{\bf {float A[L1][L2];
	
		struct event S[L1][L2];
		
		int i,j;
		
		for (i=0;i<L1;i++)
		
			\qquad for (j=0;j<L2;j++)
			
				\qquad \qquad CLEAR(S[i][j]);
				
	for (i=0;i<L1;i++) POST(S[i][0]);
	
		for (j=0;j<L2;j++) POST(S[0][j]);
		
		parfor (i=1;i<L1-1;i++)
		
			\qquad parfor (j=1;j<L2-1;j++) \{
			
				\qquad \qquad WAIT(S[i-1][j]);
				
				\qquad \qquad WAIT(S[i][j-1]);
				
				\qquad \qquad A[i][j]=(A[i-1][j]+A[i][j-1]+A[i+1][j]+A[i][j+1])/4;
				
				\qquad \qquad POST(S[i][j]);
				
			\qquad \} }}
	
	Здесь осуществляется запуск конвейера: сначала только 1 процесс может выполняться и с 
каждым шагом работы программы всё большее число процессов будут вовлечены в работу. Тем самым
получаем ускорение за счёт параллельной работы программы по сравнению с последовательным.

	В 1978 году был предложен механизм сообщений для того, чтобы уйти от разделяемой памяти, что
было достаточно узким местом. Были предложены 2 функции для реализации:
	\begin{enumerate}
		\item $SEND\mbox{ }(destination,\&message,nsize)$
		\item $RECIEVE\mbox{ }([source],\&message,nsize)$
	\end{enumerate}
	
	Сообщения бывают двух типов:
	\begin{enumerate}
		\item Буферизуемые
		\item Небуферизуемые
	\end{enumerate}
	
	Рассмотрим пример:
	
	{\bf {\#define nsize 4
	
		typedef int message[nsize];
		
		\#define N 100
	\newline
	\newline
	producer() \{
	
		message m;
		
		int item;
		
		while (TRUE) \{
		
			\qquad RECEIVE(consumer,\&m,nsize);
			
			\qquad produce\_item(\&item);
			
			\qquad build\_message(\&m,item);
			
			\qquad SEND(consumer,\&m,nsize);
			
		\}
	\newline
	\}
	\newline
	consumer() \{
	
		message m;
		
		int i,item;
		
		for (i=0;i<N;i++) SEND(producer,\&m,nsize);
		
		while (TRUE) \{
		
			\qquad RECEIVE(producer,\&m,nsize);
			
			\qquad extract\_item(\&m,item);
			
			\qquad SEND(producer,\&m,nsize);
			
			\qquad consume\_item(item);
			
		\}
	\newline
	\} }}
	
	Теперь перейдём к задаче читателей и писателей. Попробуем реализовать её с помощью
двоичных семафоров:

	{\bf {int reader=0;
	
		semaphore s=1;
		
		semaphore reader=1;
		
		semaphore writer=1;
	\newline
	\newline
	writer\_enter() \{
	
		P(writer);
		
		P(reader);
	\newline
	\}
	\newline
	writer\_exit() \{
	
		V(reader);
		
		V(writer);
	\newline
	\} 
	\newline
	reader\_enter() \{
	
		P(writer);
		
		P(S);
		
		readers++;
		
		if (readers==1) P(reader);
		
		V(S);
		
		V(writer);
	\newline	
	\}
	\newline
	reader\_exit() \{
	
		P(S);
		
		readers--;
		
		if (readers==0) V(reader);
		
		V(S);
	\newline	
	\} }}
	
	Также есть ещё классическая задача обедающих философов. Есть несколько философов, тарелка со
спагетти и у каждого философа есть вилка слева и вилка справа. Философы сидят за круглым столом.
В любой момент времени философ может захотеть покушать: он берёт правую вилку, берёт левую и 
приступает к трапезе. Чтобы не было deadlockа, вводится семафор на вилку.

	Существуют накладки при переключении процессов. Для борьбы с этим можно использовать
семафоры. Аналогично поступают и при работе с КЭШ-памятью: в некоторых операционных системах
(например, в MAC OS) существуют подсказки для управления работой процессов в критических
секциях.
	\section {\bf Распределённая общая память DSM}
	\centerline{26 марта 2010 г.\footnote{Лектор отжёг - вывел на экран
	документ в Worde и его скролил всю лекцию}}
	Реализовать работу с распределённой общей памятью гораздо труднее, чем в случае с 
виртуальной.

	\subsection {\bf Достоинства DSM}
	\begin{enumerate}
		\item Удобство программирования
		\item Суммарный объём памяти может быть огромным
		\item DSM-системы могут наращиваться практически беспредельно
		\item Программы пишутся аналогично программам для мултипроцессорных систем
	\end{enumerate}
	Всё хорошо, но есть обман пользователя: такие машины тут же попали в top 500, а проверка
для попадания туда осуществлялась на ассемблерных программах (т.е. допустим всё эффективно, а
компиляторы приблизятся к этому не могут). Когда машины начали развиваться (размеры дошли до
десятков процессоров), выяснилось, что на них сложно программировать.

	\subsection {\bf Алгоритмы реализации DSM}
	Существуют следующие проблемы:
	\begin{enumerate}
		\item как поддерживать информацию о расположении удалённых данных
		\item как снизить коммункиационные задержки (алгоритмы изгнания), т.е. как реже
		обращаться к системе через коммуникационные службы. Добиться этого можно с помощью
		разделяемых данных.
	\end{enumerate}
	Отсюда вытекает несколько алгоритмов:\footnote{Все эти алгоритмы не годятся для 
использования}
	\begin{enumerate}
		\item {\em Алгоритм с центральным сервером.} Вся работа идёт через центральный сервер,
		являющийся узким местом.
		\item {\em Миграционный алгоритм.} Идея: передать действие тому, у кого под руками
		память. Реализация мало отличается от страничной памяти. Принципиальное различие между
		DSM и обычной памятью: в случае с DSM страница памяти может быть нужна и диску (в 
		отличие от обычной памяти), эффект трешинга также присутствует. Реализация этого
		алгоритма возможна с использованием аппаратуры. Информация в одном месте $\rightarrow$ 
		неэффективен.
		\item {\em Алгоритм размножения для чтения}. Такой алгоритм вполне приемлем 
		(одновременно может писать только 1), но для реальных программ не подходит.
		\item {\em Алгоритм размножения для чтения и для записи}. Этот алгоритм всё равно не
		эффективен $\rightarrow$ нельзя эффективно реализовать DSM, не поменяв работу с памятью.
	\end{enumerate}
	Проблемы остаются: как работать с надёжностью?
	\subsection {\bf Модели консистентности}
	Обычное дело - {\em строгая консистентность}: из ячейки читаем то последнее значение, которое мы
туда записали.

	Рассмотрим мультипроцессор. Один процессор записал значение переменной, а чуть позже другой
её прочитал (за это время не успело обновиться это значение в кэше $\rightarrow$ будет считано
не последнее значение). В этом случае имеем дело с нестрогой консистентностью.

	Рассмотрим модели консистентности по мере ухода от строгой:
	\begin{enumerate}
		\item {\em Последовательная консистентность.} Результат выполнения такой же, как если бы
		все операторы выполнялись бы в какой-нибудь последовательности.
		
		Рассмотрим пример:
		
		$\begin{array}{cccccc}
		P1: & W(x)1 & & & W(y)1 \\
		P2: & & & W(z)1 \\
		P3: & & R(x)0 & R(y)0 & R(z)1 & R(y)0 \\
		P4: & & R(x)0 & R(y)1 & R(z)1 & R(x)1 \\
		\end{array}$
		
		Здесь всё хорошо.
		
		$\begin{array}{cccccc}
		P1: & W(x)1 & & & W(y)1 \\
		P2: & & & W(z)1 \\
		P3: & & R(x)0 & R(y)1 & R(z)0 & R(y)1 \\
		P4: & & R(x)1 & R(y)1 & R(z)0 & R(y)1 \\
		\end{array}$
		
		Это самый строгий алгоритм.
		
		Возможны разные реализации: централизованные и децентрализованные, но будем
	предпочитать децентрализованный алгоритм. Если рассмотреть централизованный, то у нас есть
	координатор и то, что первое ему пришло, обратно ушло всем. Те, кто послал изменения 
	переменной, должны дождаться подтверждения, иначе будет ошибка. Если же у нас есть
	неделимые широковещательные рассылки, то всё равно не можем двигаться дальше, пока не
	дойдёт до нас подтверждение. Главный принцип: всем изменения доходят в одном порядке,
	и необходимо дождаться подтверждения своего изменения.
		\item {\em Причинная консистентность.} Записи делят на: 
			\begin{itemize}
				\item причинно-следственные
				\item причинно-зависимые.
			\end{itemize}
		В случае с DSM вместо причинно-зависимых берём потенциально причинно-зависимые.
	Основная идея реализации: все модификации переменных нумеруются.
		\item {\em PRAM-консистентность.} Записи, которые делает процессор, должны быть видны всем
		и сразу, но порядок произволен. Не ждём никаких ответов. Возможны противоречивые
		ситуации.
		\item {\em Процессорная консистентность.} Добавилась когерентность памяти - должен быть
		виден одинаковый порядок для всех. Решение -- метод обгона. Можно и с помощью одного
		координатора (централизованно), а можно и децентрализованно.
		\item {\em Слабая консистентность.} Главная идея этой и последующих двух моделей: 
		использовать помимо обычных	синхронизационные переменные, обеспечивать нужное видение 
		переменных. С помощью этого	удаётся обеспечить вполне приемлемые по эффективности 
		решения. Также только когда	встретятся операции синхронизации, необходимо выслать
		значения из КЭШа. 
		
		У данной модели синхронизация имеет 2 смысла: то, что ты наменял, и то, что наменяли 
		другие. Одной операции выталкивания недостаточно. Пример:
		$\begin{array}{ccccccc}
		P1: & W(x)1 & W(x)2 & S \\
		P2: & & & & R(x)1 & R(x)2 & S \\
		P3: & & & & R(x)2 & R(x)1 & S\\
		\end{array}$
		
		Это был пример допустимой последовательности событий.
		
		$\begin{array}{cccccc}
		P1: & W(x)1 & W(x)2 & S \\
		P2: & & & & S & R(x)1 \\
		\end{array}$
		
		А это пример недопустимой операции.
		
		Основное правило работы с синхронизационными переменными -- доступ к синхронизационным 
		переменным определяется моделью последовательно	консистентности
	\end{enumerate}
\end{document}
